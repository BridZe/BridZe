{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45344d9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import cv2\n",
    "import cvlib as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "from tqdm.notebook import tqdm\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "CROP_SIZE = (48,48)\n",
    "import asyncio\n",
    "import telegram\n",
    "import nest_asyncio \n",
    "nest_asyncio.apply()\n",
    "bot = telegram.Bot(token=\"6441009419:AAGeU_ZUW6pxvqAOwIcIA8-PH8RLRPgb9rQ\")\n",
    "chat_id = \"5862996909\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42464e55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataHandle:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        DataHandle class for handling image data processing and saving.\n",
    "\n",
    "        This class provides methods to detect faces in images, crop and resize them,\n",
    "        and save the processed images along with corresponding emotion labels.\n",
    "\n",
    "        \"\"\"\n",
    "        self.db = []  # A list to store processed image paths and labels\n",
    "        self.img = None\n",
    "        self.X_position = (0, 0)\n",
    "        self.Y_position = (0, 0)\n",
    "        self.curr_emotion = ''\n",
    "        self.new_file_path = \"\"\n",
    "\n",
    "    def _save_crop_img(self):\n",
    "        \"\"\"\n",
    "        Crop and save the detected face region from the image.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if cropping and saving are successful, False otherwise.\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            img = self.img.copy()\n",
    "            roi = img[\n",
    "                self.Y_position[0]:self.Y_position[1],\n",
    "                self.X_position[0]:self.X_position[1],\n",
    "            ]\n",
    "            img = cv2.resize(roi, CROP_SIZE, interpolation=cv2.INTER_CUBIC)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            self.img = img\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    def _detect_face(self, img_path):\n",
    "        \"\"\"\n",
    "        Detect a face in the given image.\n",
    "\n",
    "        Args:\n",
    "            img_path (str): Path to the image file.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if a face is detected, False otherwise.\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.img = cv2.imread(img_path)\n",
    "            faces, _ = cv.detect_face(self.img, enable_gpu=False)\n",
    "            self.X_position = faces[0][0], faces[0][2]\n",
    "            self.Y_position = faces[0][1], faces[0][3]\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    def _random_name(self):\n",
    "        \"\"\"\n",
    "        Generate a random alphanumeric string as a name.\n",
    "\n",
    "        Returns:\n",
    "            str: A randomly generated name.\n",
    "\n",
    "        \"\"\"\n",
    "        rand_int = list(map(str, np.random.randint(low=0, high=9, size=7)))\n",
    "        lst = list(map(chr, np.random.randint(low=97, high=122, size=35))) + rand_int\n",
    "        shuffle(lst)\n",
    "        return \"\".join(lst)\n",
    "\n",
    "    def work(self, img_path, emo):\n",
    "        \"\"\"\n",
    "        Process the image and save it with the provided emotion label.\n",
    "\n",
    "        Args:\n",
    "            img_path (str): Path to the image file.\n",
    "            emo (str): Emotion label for the image.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if processing and saving are successful, False otherwise.\n",
    "\n",
    "        \"\"\"\n",
    "        self.curr_emotion = emo\n",
    "        if self._detect_face(img_path) and self._save_crop_img():\n",
    "            if self.img.shape == CROP_SIZE:\n",
    "                self.new_file_path = f\"./dataset/{self.curr_emotion}_{self._random_name()}.jpg\"\n",
    "                self.db.append({\"path\": self.new_file_path, \"label\": self.curr_emotion})\n",
    "                cv2.imwrite(self.new_file_path, self.img)\n",
    "                return True\n",
    "            else:\n",
    "                return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89239afb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry', 'fear', 'happy', 'neutral', 'sad']\n",
      "['./pre_dataset/angry/', './pre_dataset/fear/', './pre_dataset/happy/', './pre_dataset/neutral/', './pre_dataset/sad/']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Message(channel_chat_created=False, chat=Chat(first_name='SungWook', id=5862996909, last_name='Jung', type=<ChatType.PRIVATE>), date=datetime.datetime(2023, 8, 17, 21, 30, 25, tzinfo=<UTC>), delete_chat_photo=False, from_user=User(first_name='jupyterbot', id=6441009419, is_bot=True, username='oceanstarbot'), group_chat_created=False, message_id=33, supergroup_chat_created=False, text='주피터 완료')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a DataHandle instance\n",
    "dbHandle = DataHandle()\n",
    "\n",
    "# Get the list of subdirectories in the \"./pre_dataset/\" directory\n",
    "path_dir_lst = os.listdir(\"./pre_dataset/\")\n",
    "print(path_dir_lst)\n",
    "\n",
    "# Create a list of folder paths for each emotion category\n",
    "folder_lst = [\n",
    "    f'./pre_dataset/{e}/'\n",
    "    for e in path_dir_lst\n",
    "]\n",
    "print(folder_lst)\n",
    "\n",
    "# Process images in each folder and save to the database\n",
    "for emo, folder in zip(path_dir_lst, folder_lst):\n",
    "    try:\n",
    "        # Get a list of image file paths in the current folder\n",
    "        img_list = glob.glob(os.path.join(folder) + \"*.jpg\")\n",
    "        img_list = list(map(lambda x: x.replace(\"\\\\\", '/'), img_list))\n",
    "        \n",
    "        # Process each image and save to the database\n",
    "        for img_path in img_list:\n",
    "            dbHandle.work(img_path, emo)\n",
    "    except:\n",
    "        # Handle errors by sending a message using the Telegram bot\n",
    "        asyncio.run(bot.send_message(chat_id=chat_id, text=\"An error occurred\"))\n",
    "        \n",
    "# Save the database to a CSV file\n",
    "pd.DataFrame(dbHandle.db).to_csv(\"dataset.csv\", index=False)\n",
    "\n",
    "# Send a completion message to Telegram\n",
    "asyncio.run(bot.send_message(chat_id=chat_id, text=\"Jupyter Notebook execution completed\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
